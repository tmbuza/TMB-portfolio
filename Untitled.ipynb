{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e710637a-6c0f-434c-a863-d4810d92d32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in /Users/tmbuza/opt/anaconda3/envs/biobakery3/lib/python3.9/site-packages (1.12.2)\n",
      "Requirement already satisfied: tzlocal>=1.1 in /Users/tmbuza/opt/anaconda3/envs/biobakery3/lib/python3.9/site-packages (from streamlit) (4.2)\n",
      "Requirement already satisfied: pympler>=0.9 in /Users/tmbuza/opt/anaconda3/envs/biobakery3/lib/python3.9/site-packages (from streamlit) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil in /Users/tmbuza/opt/anaconda3/envs/biobakery3/lib/python3.9/site-packages (from streamlit) (2.8.2)\n",
      "Requirement already satisfied: cachetools>=4.0 in /Users/tmbuza/opt/anaconda3/envs/biobakery3/lib/python3.9/site-packages (from streamlit) (4.2.4)\n",
      "Requirement already satisfied: validators>=0.2 in /Users/tmbuza/opt/anaconda3/envs/biobakery3/lib/python3.9/site-packages (from streamlit) (0.20.0)\n",
      "Requirement already satisfied: importlib-metadata>=1.4 in /Users/tmbuza/opt/anaconda3/envs/biobakery3/lib/python3.9/site-packages (from streamlit) (4.11.3)\n",
      "Collecting protobuf<4,>=3.12\n",
      "  Using cached protobuf-3.20.1-cp39-cp39-macosx_10_9_x86_64.whl (962 kB)\n",
      "Requirement already satisfied: toml in /Users/tmbuza/opt/anaconda3/envs/biobakery3/lib/python3.9/site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/tmbuza/opt/anaconda3/envs/biobakery3/lib/python3.9/site-packages (from streamlit) (12.3.0)\n",
      "Requirement already satisfied: pandas>=0.21.0 in /Users/tmbuza/opt/anaconda3/envs/biobakery3/lib/python3.9/site-packages (from streamlit) (1.4.2)\n",
      "Requirement already satisfied: altair>=3.2.0 in /Users/tmbuza/opt/anaconda3/envs/biobakery3/lib/python3.9/site-packages (from streamlit) (4.2.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19 in /Users/tmbuza/opt/anaconda3/envs/biobakery3/lib/python3.9/site-packages (from streamlit) (3.1.27)\n",
      "Requirement already satisfied: pyarrow>=4.0 in /Users/tmbuza/opt/anaconda3/envs/biobakery3/lib/python3.9/site-packages (from streamlit) (6.0.1)\n",
      "Requirement already satisfied: packaging>=14.1 in /Users/tmbuza/opt/anaconda3/envs/biobakery3/lib/python3.9/site-packages (from streamlit) (21.3)\n",
      "Requirement already satisfied: semver in /Users/tmbuza/opt/anaconda3/envs/biobakery3/lib/python3.9/site-packages (from streamlit) (2.13.0)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0.0 in /Users/tmbuza/opt/anaconda3/envs/biobakery3/lib/python3.9/site-packages (from streamlit) (4.2.0)\n",
      "Requirement already satisfied: pydeck>=0.1.dev5 in /Users/tmbuza/opt/anaconda3/envs/biobakery3/lib/python3.9/site-packages (from streamlit) (0.8.0b1)\n",
      "Requirement already satisfied: blinker>=1.0.0 in /Users/tmbuza/opt/anaconda3/envs/biobakery3/lib/python3.9/site-packages (from streamlit) (1.5)\n",
      "Requirement already satisfied: numpy in /Users/tmbuza/opt/anaconda3/envs/biobakery3/lib/python3.9/site-packages (from streamlit) (1.22.3)\n",
      "Requirement already satisfied: tornado>=5.0 in /Users/tmbuza/opt/anaconda3/envs/biobakery3/lib/python3.9/site-packages (from streamlit) (6.1)\n",
      "Requirement already satisfied: click>=7.0 in /Users/tmbuza/opt/anaconda3/envs/biobakery3/lib/python3.9/site-packages (from streamlit) (8.1.3)\n",
      "Requirement already satisfied: requests>=2.4 in /Users/tmbuza/opt/anaconda3/envs/biobakery3/lib/python3.9/site-packages (from streamlit) (2.25.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/tmbuza/opt/anaconda3/envs/biobakery3/lib/python3.9/site-packages (from streamlit) (9.1.0)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /Users/tmbuza/opt/anaconda3/envs/biobakery3/lib/python3.9/site-packages (from altair>=3.2.0->streamlit) (4.4.0)\n",
      "Requirement already satisfied: jinja2 in /Users/tmbuza/opt/anaconda3/envs/biobakery3/lib/python3.9/site-packages (from altair>=3.2.0->streamlit) (3.0.3)\n",
      "Requirement already satisfied: entrypoints in /Users/tmbuza/opt/anaconda3/envs/biobakery3/lib/python3.9/site-packages (from altair>=3.2.0->streamlit) (0.4)\n",
      "Requirement already satisfied: toolz in /Users/tmbuza/opt/anaconda3/envs/biobakery3/lib/python3.9/site-packages (from altair>=3.2.0->streamlit) (0.12.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/tmbuza/opt/anaconda3/envs/biobakery3/lib/python3.9/site-packages (from gitpython!=3.1.19->streamlit) (4.0.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/tmbuza/opt/anaconda3/envs/biobakery3/lib/python3.9/site-packages (from importlib-metadata>=1.4->streamlit) (3.8.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/tmbuza/opt/anaconda3/envs/biobakery3/lib/python3.9/site-packages (from packaging>=14.1->streamlit) (3.0.8)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/tmbuza/opt/anaconda3/envs/biobakery3/lib/python3.9/site-packages (from pandas>=0.21.0->streamlit) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/tmbuza/opt/anaconda3/envs/biobakery3/lib/python3.9/site-packages (from python-dateutil->streamlit) (1.15.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/tmbuza/opt/anaconda3/envs/biobakery3/lib/python3.9/site-packages (from requests>=2.4->streamlit) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/tmbuza/opt/anaconda3/envs/biobakery3/lib/python3.9/site-packages (from requests>=2.4->streamlit) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/tmbuza/opt/anaconda3/envs/biobakery3/lib/python3.9/site-packages (from requests>=2.4->streamlit) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/tmbuza/opt/anaconda3/envs/biobakery3/lib/python3.9/site-packages (from requests>=2.4->streamlit) (1.26.9)\n",
      "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /Users/tmbuza/opt/anaconda3/envs/biobakery3/lib/python3.9/site-packages (from rich>=10.11.0->streamlit) (0.9.1)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /Users/tmbuza/opt/anaconda3/envs/biobakery3/lib/python3.9/site-packages (from rich>=10.11.0->streamlit) (2.12.0)\n",
      "Requirement already satisfied: pytz-deprecation-shim in /Users/tmbuza/opt/anaconda3/envs/biobakery3/lib/python3.9/site-packages (from tzlocal>=1.1->streamlit) (0.1.0.post0)\n",
      "Requirement already satisfied: decorator>=3.4.0 in /Users/tmbuza/opt/anaconda3/envs/biobakery3/lib/python3.9/site-packages (from validators>=0.2->streamlit) (4.4.2)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/tmbuza/opt/anaconda3/envs/biobakery3/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19->streamlit) (5.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/tmbuza/opt/anaconda3/envs/biobakery3/lib/python3.9/site-packages (from jinja2->altair>=3.2.0->streamlit) (2.1.1)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /Users/tmbuza/opt/anaconda3/envs/biobakery3/lib/python3.9/site-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit) (0.18.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /Users/tmbuza/opt/anaconda3/envs/biobakery3/lib/python3.9/site-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit) (21.4.0)\n",
      "Requirement already satisfied: tzdata in /Users/tmbuza/opt/anaconda3/envs/biobakery3/lib/python3.9/site-packages (from pytz-deprecation-shim->tzlocal>=1.1->streamlit) (2022.1)\n",
      "Installing collected packages: protobuf\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.21.5\n",
      "    Uninstalling protobuf-4.21.5:\n",
      "      Successfully uninstalled protobuf-4.21.5\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.6.0 requires h5py~=3.1.0, but you have h5py 3.6.0 which is incompatible.\n",
      "tensorflow 2.6.0 requires numpy~=1.19.2, but you have numpy 1.22.3 which is incompatible.\n",
      "tensorflow 2.6.0 requires typing-extensions~=3.7.4, but you have typing-extensions 4.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed protobuf-3.20.1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Descriptors cannot not be created directly.\nIf this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\nIf you cannot immediately regenerate your protos, some other possible workarounds are:\n 1. Downgrade the protobuf package to 3.20.x or lower.\n 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n\nMore information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[1;32m      6\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install streamlit\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstreamlit\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mst\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstreamlit_lottie\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m st_lottie\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/biobakery3/lib/python3.9/site-packages/streamlit/__init__.py:48\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstreamlit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m logger \u001b[38;5;28;01mas\u001b[39;00m _logger\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstreamlit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config \u001b[38;5;28;01mas\u001b[39;00m _config\n\u001b[0;32m---> 48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstreamlit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproto\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mRootContainer_pb2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RootContainer\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstreamlit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mruntime\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msecrets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Secrets, SECRETS_FILE_LOC\n\u001b[1;32m     51\u001b[0m _LOGGER \u001b[38;5;241m=\u001b[39m _logger\u001b[38;5;241m.\u001b[39mget_logger(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroot\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/biobakery3/lib/python3.9/site-packages/streamlit/proto/RootContainer_pb2.py:33\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m _sym_db \u001b[38;5;241m=\u001b[39m _symbol_database\u001b[38;5;241m.\u001b[39mDefault()\n\u001b[1;32m     17\u001b[0m DESCRIPTOR \u001b[38;5;241m=\u001b[39m _descriptor\u001b[38;5;241m.\u001b[39mFileDescriptor(\n\u001b[1;32m     18\u001b[0m   name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstreamlit/proto/RootContainer.proto\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     19\u001b[0m   package\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m   serialized_pb\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m#streamlit/proto/RootContainer.proto*&\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124mRootContainer\u001b[39m\u001b[38;5;130;01m\\x12\u001b[39;00m\u001b[38;5;130;01m\\x08\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\x04\u001b[39;00m\u001b[38;5;124mMAIN\u001b[39m\u001b[38;5;130;01m\\x10\u001b[39;00m\u001b[38;5;130;01m\\x00\u001b[39;00m\u001b[38;5;130;01m\\x12\u001b[39;00m\u001b[38;5;130;01m\\x0b\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\x07\u001b[39;00m\u001b[38;5;124mSIDEBAR\u001b[39m\u001b[38;5;130;01m\\x10\u001b[39;00m\u001b[38;5;130;01m\\x01\u001b[39;00m\u001b[38;5;130;01m\\x62\u001b[39;00m\u001b[38;5;130;01m\\x06\u001b[39;00m\u001b[38;5;124mproto3\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     24\u001b[0m )\n\u001b[1;32m     26\u001b[0m _ROOTCONTAINER \u001b[38;5;241m=\u001b[39m _descriptor\u001b[38;5;241m.\u001b[39mEnumDescriptor(\n\u001b[1;32m     27\u001b[0m   name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRootContainer\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     28\u001b[0m   full_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRootContainer\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     29\u001b[0m   filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     30\u001b[0m   file\u001b[38;5;241m=\u001b[39mDESCRIPTOR,\n\u001b[1;32m     31\u001b[0m   create_key\u001b[38;5;241m=\u001b[39m_descriptor\u001b[38;5;241m.\u001b[39m_internal_create_key,\n\u001b[1;32m     32\u001b[0m   values\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m---> 33\u001b[0m     \u001b[43m_descriptor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEnumValueDescriptor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMAIN\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m      \u001b[49m\u001b[43mserialized_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcreate_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_descriptor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_internal_create_key\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     38\u001b[0m     _descriptor\u001b[38;5;241m.\u001b[39mEnumValueDescriptor(\n\u001b[1;32m     39\u001b[0m       name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSIDEBAR\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, number\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     40\u001b[0m       serialized_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     41\u001b[0m       \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     42\u001b[0m       create_key\u001b[38;5;241m=\u001b[39m_descriptor\u001b[38;5;241m.\u001b[39m_internal_create_key),\n\u001b[1;32m     43\u001b[0m   ],\n\u001b[1;32m     44\u001b[0m   containing_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     45\u001b[0m   serialized_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     46\u001b[0m   serialized_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m39\u001b[39m,\n\u001b[1;32m     47\u001b[0m   serialized_end\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m77\u001b[39m,\n\u001b[1;32m     48\u001b[0m )\n\u001b[1;32m     49\u001b[0m _sym_db\u001b[38;5;241m.\u001b[39mRegisterEnumDescriptor(_ROOTCONTAINER)\n\u001b[1;32m     51\u001b[0m RootContainer \u001b[38;5;241m=\u001b[39m enum_type_wrapper\u001b[38;5;241m.\u001b[39mEnumTypeWrapper(_ROOTCONTAINER)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/biobakery3/lib/python3.9/site-packages/google/protobuf/descriptor.py:755\u001b[0m, in \u001b[0;36mEnumValueDescriptor.__new__\u001b[0;34m(cls, name, index, number, type, options, serialized_options, create_key)\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, name, index, number,\n\u001b[1;32m    753\u001b[0m             \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# pylint: disable=redefined-builtin\u001b[39;00m\n\u001b[1;32m    754\u001b[0m             options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, serialized_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, create_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 755\u001b[0m   \u001b[43m_message\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMessage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_CheckCalledFromGeneratedFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    756\u001b[0m   \u001b[38;5;66;03m# There is no way we can build a complete EnumValueDescriptor with the\u001b[39;00m\n\u001b[1;32m    757\u001b[0m   \u001b[38;5;66;03m# given parameters (the name of the Enum is not known, for example).\u001b[39;00m\n\u001b[1;32m    758\u001b[0m   \u001b[38;5;66;03m# Fortunately generated files just pass it to the EnumDescriptor()\u001b[39;00m\n\u001b[1;32m    759\u001b[0m   \u001b[38;5;66;03m# constructor, which will ignore it, so returning None is good enough.\u001b[39;00m\n\u001b[1;32m    760\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: Descriptors cannot not be created directly.\nIf this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\nIf you cannot immediately regenerate your protos, some other possible workarounds are:\n 1. Downgrade the protobuf package to 3.20.x or lower.\n 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n\nMore information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates"
     ]
    }
   ],
   "source": [
    "#######################################\n",
    "# ----Tools and Page setup----\n",
    "#######################################\n",
    "import json\n",
    "import requests\n",
    "!pip install streamlit\n",
    "import streamlit as st\n",
    "from streamlit_lottie import st_lottie\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "from PIL import Image\n",
    "\n",
    "# Find emojis here: https://www.webfx.com/tools/emoji-cheat-sheet/. \n",
    "st.set_page_config(page_title=\"TMB Portfolio\", page_icon=\":sparkles:\", layout = \"wide\")\n",
    "\n",
    "# Using local CSS\n",
    "def local_css(file_name):\n",
    "    with open(file_name) as f:\n",
    "        st.markdown(f\"<style>{f.read()}</style>\", unsafe_allow_html=True)\n",
    "\n",
    "local_css(\"style/style.css\")\n",
    "\n",
    "\n",
    "#######################################\n",
    "# ----Assets----\n",
    "#######################################\n",
    "\n",
    "# For Professional Passion\n",
    "omics_ml = Image.open(\"imgvideo/omics_ml.png\")\n",
    "wcloud1 = Image.open(\"imgvideo/wordcloud.png\")\n",
    "gwas = Image.open(\"imgvideo/gwas_in_biome.png\")\n",
    "\n",
    "# For microbiome data analysis\n",
    "gif1 = open(\"imgvideo/abund_bar.gif\")\n",
    "\n",
    "# For quantitative data analysis\n",
    "fig1 = Image.open(\"imgvideo/climate_nasa.png\")\n",
    "\n",
    "vid1 = open(\"imgvideo/climate_spiral_nasa.mp4\", \"rb\").read()\n",
    "\n",
    "\n",
    "# For the NGS section\n",
    "fig2 = Image.open(\"imgvideo/dna_composition.png\")\n",
    "\n",
    "#######################################\n",
    "# ---- Header with salutation and introduction----\n",
    "#######################################\n",
    "with st.container():\n",
    "  header1, header2 = st.columns((2, 1))\n",
    "  with header1:\n",
    "    st.warning(\":warning:... this is work in progress, not complete or proofread yet.\")\n",
    "    st.subheader(\"Hi, I am Teresia Mrema-Buza:wave:\")\n",
    "    st.title(\"A Data Science, Bioinformatics, and Computational Biology Enthusiast, Consultant, and Mentor.\") \n",
    "    # Insert a divider\n",
    "    st.header(\"Welcome to my Portfolio!\")\n",
    "\n",
    "    st.markdown(\n",
    "    \"\"\"\n",
    "    #### I recently started compiling my minimal `PORTFOLIO` to remind myself of what I can do or share to support the fields of Science and Technology. With this reminder, I can dedicate more energy to developing practical user guides in my areas of expertise to help anyone interested in what I do.\n",
    "    \n",
    "    #### Feel free to explore my passion in this portfolio. `KARIBU`:tada:\n",
    "    \"\"\")\n",
    "    st.write(\"---\")\n",
    "  with header2:\n",
    "    st.markdown(\n",
    "    \"\"\"\n",
    "    \"\"\")\n",
    "    \n",
    "with st.container():    \n",
    "  st.write(\"##\")\n",
    "  st.title(\":gift_heart:Professional Passion\")\n",
    "  header1, header2 = st.columns((1, 2))\n",
    "  with header1:\n",
    "    html_string1 = \"<h3 style='color:#005500; font-size:24px;'>I am passionate about developing resources for finding insights into complex data using modern techniques. Also, I am interested in providing mentorship to interested individuals, particularly in the fields related to: </h3>\"\n",
    "    st.markdown(html_string1, unsafe_allow_html=True)\n",
    "    \n",
    "    html_string2 = \"<ol> \\\n",
    "    \t<li>Microbiome Data Analysis</li> \\\n",
    "    \t<li>Machine Learning</li> \\\n",
    "    \t<li>Multi-Omics Bioinformatics</li> \\\n",
    "    \t<li>Quantitative Data Analysis</li> \\\n",
    "    \t<li>Qualitative Data Analysis</li> \\\n",
    "    \t<li>Data Tidying and Transformation</li> \\\n",
    "    \t<li>Data Visualization</li> \\\n",
    "    \t<li>Statistical Analysis</li> \\\n",
    "    \t<li>Feature Engineering</li> \\\n",
    "    \t<li>Model Selection and Training</li> \\\n",
    "    \t<li>Hyperparameter Tuning</li> \\\n",
    "    \t<li>Predictive Modeling</li> \\\n",
    "    \t<li>Deployment of Simple Models</li> \\\n",
    "    \t<li>AOB Related to Data Insights</li> \\\n",
    "    </ol>\"\n",
    "    st.markdown(html_string2, unsafe_allow_html=True)\n",
    "  \n",
    "  with header2:\n",
    "    st.success(\n",
    "      \"\"\"\n",
    "      ## Did you know?\n",
    "      ### Machine Learning & Microbiome\n",
    "      ...are fields getting lots of attention recently. PubMed metrics can prove this theory!\n",
    "      \"\"\")\n",
    "    st.image(omics_ml)\n",
    "    \n",
    "    \n",
    "# ---- WHAT I DO ----\n",
    "with st.container():\n",
    "    st.write(\"---\")\n",
    "    left_column, right_column = st.columns(2)\n",
    "    with left_column:\n",
    "        st.header(\"What I Currently Do\")\n",
    "        st.write(\"##\")\n",
    "        st.write(\n",
    "            \"\"\"\n",
    "            ### On my [GitHub account](https://github.com/tmbuza?tab=repositories):\n",
    "              - I am developing multiple practical user guides for various analyses.\n",
    "              - Most of these guides are under development in my private repositories and will be shared publicly once completed.\n",
    "              - The intended audience is users who:\n",
    "                  - ...are looking for friendly solutions to leverage their daily analytical tasks.\n",
    "                  - ...are struggling to understand how to efficiently process raw data and transform it into actionable insights.\n",
    "                  - ...are eager to learn more about going beyond traditional data analysis by integrating multiple compatible tools to achieve a more significant impact.\n",
    "                  - ...are looking for better solutions to visualize the data and create shareable reports and dashboards.\n",
    "                  - ...are looking for ways of transforming static images into interactive ones.\n",
    "                  - ...are interested in developing and deploying simple data exploratory apps.\n",
    "                  - ...are enthusiastic about developing skills to advance their career in Data Science, Machine Learning, or Bioinformatics.\n",
    "           \"\"\")\n",
    "        st.info(\n",
    "            \"\"\"\n",
    "            If what I do sounds interesting to you, [get in touch](https://complexdatainsights.com/#contactus). Also, consider subscribing to my [website](https://complexdatainsights.com) (currently under active development) to benefit from the available DIY resources. Don\\'t forget to turn on the notifications to receive updates.\n",
    "            \"\"\")\n",
    "\n",
    "    with right_column:\n",
    "        st.header(\"\")\n",
    "        st.write(\"##\")\n",
    "        st.image(fig1)\n",
    "    \n",
    "#######################################\n",
    "# ----My Projects----\n",
    "#######################################\n",
    "with st.container():  \n",
    "  st.title(\"Microbiome Bioinformatics Projects\")\n",
    "  st.write(\"---\")\n",
    "\n",
    "  column1, separator, column2 = st.columns((1, 0.5,  2)) \n",
    "  with column1:\n",
    "    st.header(\"Microbial Profiling\")\n",
    "    st.image(\"https://complexdatainsights.com/books/microbiome-analysis/end-to-end-user-guide/figures/stacked_bar_fig-.gif\")\n",
    "    st.caption(\"Simple example of Microbial relative abundance profiles at Taxon-level. This image show only the most abundant taxa and the remaining are in the other category.\")\n",
    "    \n",
    "    st.header(\"Biomarker Discovery\")    \n",
    "    st.image(\"https://complexdatainsights.com/books/microbiome-analysis/end-to-end-user-guide/figures/lefse_fig-1.png\")\n",
    "    st.caption(\"Simple example showing significant biomarkers identified using the Linear discriminant analysis Effect Size (LEfSe) based on the LDA scores\")\n",
    "    st.markdown(\"\"\"\n",
    "    \"\"\")\n",
    "    \n",
    "  with separator:\n",
    "    st.write(\"\")\n",
    "    \n",
    "  with column2:\n",
    "    st.header(\":fireworks:Achievements\")\n",
    "    st.success(\n",
    "    \"\"\"\n",
    "      ### 1. Publications\n",
    "      - [Paper 1](https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-019-2965-4): iMAP: an integrated bioinformatics and visualization pipeline for microbiome data analysis. \n",
    "        - See the current [iMAP manuscript dimensions](https://badge.dimensions.ai/details/id/pub.1117740326).\n",
    "      - [Paper 2](https://www.nature.com/articles/s41598-019-53969-7): Microbial Diversity in Bushmeat Samples Recovered from the Serengeti Ecosystem in Tanzania.\n",
    "\n",
    "\n",
    "      \n",
    "      ### 2. GitHub Repositories\n",
    "      \n",
    "      |Repo| Description| Description|\n",
    "      |-------------------------|---------------------------------------------------|-----------------|\n",
    "      | iMAP | Original Pipeline linked to [iMAP manuscript](https://rdcu.be/bIxrg) | [GitHub Page](https://tmbuza.github.io/iMAP/) |\n",
    "      > The original iMAP is being restructured and updated with more improved workflows. The updated version will replace the existing pipeline. Please consider this an ongoing process of finding better and integrated solutions for microbiome data analysis.\n",
    " \n",
    "\n",
    "     \n",
    "      ### :tada: Improved iMAP in Four-Tiers!\n",
    "           \n",
    "\n",
    "      > Investigating the role of microbial communities in health and disease requires a thorough knowledge of the entire analytical process.\n",
    "      Using the wrong approaches can cost a significant amount of dollars and make a lengthy process to achieve the desired results.\n",
    "      The Table below shows four iMAP practical user guides that systematically provide analytical support to the microbiome research community.\n",
    "      Each guide is reproducible, allowing **R-users** to follow along easily.\n",
    "\n",
    "      |Repo| Description| Repo Output|\n",
    "      |-------------------------|---------------------------------------------------|-----------------|\n",
    "      | [iMAP-PART1](https://github.com/tmbuza/iMAP-part1/) | How to Get Started with Microbiome Data Analysis | [eBook](https://complexdatainsights.com/books/microbiome-analysis/getting-started) |\n",
    "      | [iMAP-PART2](https://github.com/tmbuza/iMAP-part2/) | Bioinformatics Analysis of Microbiome Data | [eBook](https://complexdatainsights.com/books/microbiome-analysis/bioinformatics-analysis) |\n",
    "      | [iMAP-PART3](https://github.com/tmbuza/iMAP-part3/) | Data Preprocessing | [eBook](https://complexdatainsights.com/books/microbiome-analysis/data-preprocessing) |\n",
    "      | [iMAP-PART4](https://github.com/tmbuza/iMAP-part4/) | Exploratory Analysis of Microbiome Data | [eBook](https://complexdatainsights.com/books/microbiome-analysis/exploratory-analysis) |\n",
    "\n",
    "\n",
    "\n",
    "      ### 3. End-to-End Microbiome Analysis eBooks\n",
    "\n",
    "    \n",
    "      |eBook| Description| Repo Output|\n",
    "      |-------------------------|---------------------------------------------------|-----------------|\n",
    "      | SMDA | Systematic Microbiome Data Analysis (SMDA)...In progress.| [eBook 1](https://complexdatainsights.com/books/microbiome-analysis/end-to-end-user-guide/) |\n",
    "      \"\"\")\n",
    "    \n",
    "st.write(\"---\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#######################################\n",
    "#######################################\n",
    "#######################################\n",
    "with st.container():\n",
    "  st.write(\"---\")\n",
    "  st.header(\"Quantitative Data Analysis Projects\")\n",
    "  st.write(\"##\")\n",
    "  video_column, separator, text_column = st.columns((1, 0.5, 2))\n",
    "  with video_column:\n",
    "    st.info(\"Click the image below to see how \\nthe temperature is changing stepwise from 1880 to 2022!\")\n",
    "    st.video(vid1)\n",
    "    st.write(\n",
    "      \"\"\"\n",
    "      I used a custom R script to generate the MP4.\n",
    "      \"\"\")\n",
    "    st.write(\n",
    "      \"\"\"\n",
    "      ...Inspired by [`code club Youtube video tutorials`](https://riffomonas.org/code_club/) presented by Pat Schloss\\'s.\n",
    "      \"\"\")\n",
    "    \n",
    "  with separator:\n",
    "    st.write(\"\")\n",
    "    \n",
    "  with text_column:\n",
    "    st.subheader(\"Reproducible Research\")\n",
    "    st.write(\n",
    "      \"\"\"\n",
    "      **The climate data can be replaced with any quantitative or time series data to reproduce similar image.**\n",
    "      \n",
    "      - Get the same experience. I will be happy to provide you with a reproducible and easily customizable practical user guide. \n",
    "      - If you are interested in outsourcing or consulting services, I can help you get the results faster. \n",
    "      - You will also have the option to request a source code associated with the sought analysis. \n",
    "      \"\"\"\n",
    "      )\n",
    "      # - Explore a variety of climate data visualization available [**here!**](https://complexdatainsights.com/books/climate-analysis/climate-viz.html#plotly-image)\n",
    "\n",
    "\n",
    "# with st.container():\n",
    "#   video_column, text_column = st.columns((1, 2))\n",
    "#   with video_column:\n",
    "#     st.info(\"Click the image below to see how \\nthe static image was generated stepwise from 1880 to 2022!\")\n",
    "#     st.video(vid1)\n",
    "#     st.write(\n",
    "#       \"\"\"\n",
    "#      I used a custom R script to generate the MP4.\n",
    "#       \"\"\")\n",
    "\n",
    "#######################################\n",
    "#######################################\n",
    "#######################################\n",
    "with st.container():\n",
    "  st.write(\"---\")\n",
    "  st.title(\"Next Generation Sequence Exploration Projects\")\n",
    "  st.write(\"##\")\n",
    "  image_column, separator, output_column = st.columns((1, 0.5, 2))\n",
    "  with image_column:\n",
    "    st.image(fig2)\n",
    "    st.caption(\"Example of a DNA sequence with colors representing different nucleotide; A, T, C, G. How many each of these nucleotides are in a FASTA sequence?\")\n",
    "    \n",
    "    # with query_column:\n",
    "    st.header(\"APP to Count Nucleotides\")\n",
    "    st.markdown(\n",
    "    \"\"\"\n",
    "    This web app quickly computes the number of nucleotides present in a FASTA sequence.\n",
    "    `Give it a try!`\n",
    "    \"\"\"\n",
    "    )\n",
    "    \n",
    "    st.subheader('Enter query sequence in the box below')\n",
    "    sequence_input = \">Partial sequence\\nCTCAGATTGAACGCTGGCGGCAGGCCTAACACATGCAAGTCGAACGGTAGCACAGAGAGCTTGCTCTTGGGTGACGAGTGGCGGACGGGTGAGTAATGTCTGGGAAACTGCCCGATGGAGGGGGATAACTACTGGAAACGGTAGCTAATACCGCATAACGTCTACGGACCAAAGT\\GGGGGACCTTCGGGCCTCACACCATCGGATGTGCCCAGATGGGATTAGCTGGTAGGTGGGGTAACGGCTCACCTAGGCGACGATCCCTAGCTGGTCTGAGAGGAT\"\n",
    "    \n",
    "    sequence = st.text_area(\"Fasta sequence\", sequence_input, height=250)\n",
    "    sequence = sequence.splitlines()\n",
    "    sequence = sequence[1:] # Skips the sequence name (first line)\n",
    "    sequence = ''.join(sequence) # Concatenates list to string\n",
    "    \n",
    "    # with seq_column:\n",
    "    ## Print the input DNA sequence\n",
    "    st.subheader('DNA Query')\n",
    "    sequence\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "# with st.container():\n",
    "#   st.write(\"##\")\n",
    "#   text_column, figure_column = st.columns((1, 2))\n",
    "#   \n",
    "  with separator:\n",
    "    st.write(\"\")\n",
    "  with output_column:\n",
    "    st.subheader(\"App Output\")\n",
    "    \n",
    "    def DNA_nucleotide_count(seq):\n",
    "      d = dict([\n",
    "                ('A',seq.count('A')),\n",
    "                ('T',seq.count('T')),\n",
    "                ('G',seq.count('G')),\n",
    "                ('C',seq.count('C'))\n",
    "                ])\n",
    "      return d\n",
    "    \n",
    "    X = DNA_nucleotide_count(sequence)\n",
    "    \n",
    "    ### 1. Nucleotide Count\n",
    "    st.subheader('1. Observation')\n",
    "    st.write('There are  ' + str(X['A']) + ' adenine (A)')\n",
    "    st.write('There are  ' + str(X['T']) + ' thymine (T)')\n",
    "    st.write('There are  ' + str(X['G']) + ' guanine (G)')\n",
    "    st.write('There are  ' + str(X['C']) + ' cytosine (C)')\n",
    "\n",
    "    ### 2. Count Matrix\n",
    "    st.subheader('2. DataFrame')\n",
    "    df = pd.DataFrame.from_dict(X, orient='index')\n",
    "    df = df.rename({0: 'NT-Count'}, axis='columns')\n",
    "    df.reset_index(inplace=True)\n",
    "    df = df.rename(columns = {'index':'Sequence'})\n",
    "    st.write(df)\n",
    "    \n",
    "  # with figure_column:\n",
    "    # st.header(\"Nucleotides Distribution\")\n",
    "    ### 3. Graphical Distribution\n",
    "    st.subheader('3. Bar chart')\n",
    "    p = alt.Chart(df).mark_bar().encode(\n",
    "        x='Sequence',\n",
    "        y='NT-Count'\n",
    "    )\n",
    "    p = p.properties(\n",
    "        width=alt.Step(100)  # controls width of bar.\n",
    "    )\n",
    "    st.write(p)\n",
    "    st.caption(\"Bar chart showing the number of nucleotide composition in a given DNA sequence.\")\n",
    "  \n",
    "  ### Save data frame locally\n",
    "  df.to_csv(\"data/gene_seq1.csv\")\n",
    "\n",
    "\n",
    "\n",
    "st.write(\"##\")\n",
    "st.write(\"##\")\n",
    "with st.container():\n",
    "  st.write(\"---\")\n",
    "  st.header(\"Get In Touch\")\n",
    "  st.write(\n",
    "    \"\"\"\n",
    "    - Let's collaborate and work together in this world of Data Science and many more...\n",
    "    - Together we can transform complex data into **ACTIONABLE INSIGHTS**.\n",
    "    - Feel free to contact me by filling out the form below to let me know if we need to collaborate or need a mentor in specific fields of my expertise.\n",
    "    \"\"\")\n",
    "  \n",
    "  # Contact Documentation: https://formsubmit.co/ Change the email address\n",
    "  contact_form = \"\"\"\n",
    "  <form action=\"https://formsubmit.co/ndelly@gmail.com\" method=\"POST\">\n",
    "    <input type=\"hidden\" name=\"_captcha\" value=\"false\">\n",
    "    <input type=\"text\" name=\"name\" placeholder=\"Your name\" required>\n",
    "    <input type=\"email\" name=\"email\" placeholder=\"Your email\" required>\n",
    "    <textarea name=\"message\" placeholder=\"Your message here\" required></textarea>\n",
    "    <button type=\"submit\">Send</button>\n",
    "  </form>\n",
    "  \"\"\"\n",
    "  \n",
    "# Use local css file\n",
    "  def local_css(file_name):\n",
    "    with open(file_name) as f:\n",
    "      st.markdown(f\"<style>{f.read()}</style>\", unsafe_allow_html=True)\n",
    "      \n",
    "  local_css(\"style/style.css\")\n",
    "  \n",
    "  \n",
    "  left_column, right_column = st.columns(2)\n",
    "  with left_column:\n",
    "    st.markdown(contact_form, unsafe_allow_html=True)\n",
    "  with right_column:\n",
    "    # st.empty()\n",
    "    st.image(\"https://complexdatainsights.com/wp-content/uploads/2020/09/contactNewk.png\")\n",
    "\n",
    "\n",
    "##################################\n",
    "# st.balloons()\n",
    "##################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9e7594-9290-497f-9883-c5d5b177f7e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
